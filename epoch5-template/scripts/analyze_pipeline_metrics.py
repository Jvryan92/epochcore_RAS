"""
Analyze pipeline metrics to enable self-improvement
"""
import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Any

class PipelineOptimizer:
    def __init__(self):
        self.metrics_file = ".github/pipeline_metrics.json"
        self.config_file = ".github/workflows/epoch5-pipeline.yml"
        self.optimization_history = ".github/optimization_history.json"
        
    def analyze_pipeline_metrics(self) -> Dict[str, Any]:
        """Analyze pipeline performance metrics"""
        # Get historical pipeline runs
        runs = self._get_workflow_runs()
        
        # Calculate key metrics
        metrics = {
            "avg_duration": self._calculate_average_duration(runs),
            "success_rate": self._calculate_success_rate(runs),
            "flaky_jobs": self._identify_flaky_jobs(runs),
            "bottleneck_jobs": self._identify_bottlenecks(runs),
            "resource_usage": self._analyze_resource_usage(runs),
            "cache_effectiveness": self._analyze_cache_hits(runs)
        }
        
        # Save metrics
        self._save_metrics(metrics)
        return metrics
        
    def optimize_pipeline(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """Generate pipeline optimizations based on metrics"""
        optimizations = {
            "job_parallelization": self._optimize_parallelization(metrics),
            "cache_strategy": self._optimize_caching(metrics),
            "resource_allocation": self._optimize_resources(metrics),
            "test_distribution": self._optimize_test_distribution(metrics),
            "conditional_jobs": self._optimize_conditionals(metrics)
        }
        
        # Save optimization history
        self._save_optimization_history(optimizations)
        return optimizations
        
    def _get_workflow_runs(self) -> List[Dict[str, Any]]:
        """Get historical workflow runs from GitHub API"""
        # Implementation would use GitHub API to fetch workflow runs
        return []
        
    def _calculate_average_duration(self, runs: List[Dict[str, Any]]) -> float:
        """Calculate average pipeline duration"""
        if not runs:
            return 0.0
            
        durations = [
            (run["completed_at"] - run["started_at"]).total_seconds()
            for run in runs
            if run["status"] == "completed"
        ]
        return sum(durations) / len(durations) if durations else 0.0
        
    def _calculate_success_rate(self, runs: List[Dict[str, Any]]) -> float:
        """Calculate pipeline success rate"""
        if not runs:
            return 0.0
            
        successful = sum(1 for run in runs if run["conclusion"] == "success")
        return successful / len(runs)
        
    def _identify_flaky_jobs(self, runs: List[Dict[str, Any]]) -> List[str]:
        """Identify jobs with inconsistent results"""
        job_results = {}
        for run in runs:
            for job in run["jobs"]:
                if job["name"] not in job_results:
                    job_results[job["name"]] = []
                job_results[job["name"]].append(job["conclusion"])
                
        flaky_jobs = []
        for job_name, results in job_results.items():
            success_rate = results.count("success") / len(results)
            if 0.3 < success_rate < 0.95:  # Consider jobs with mixed success rates
                flaky_jobs.append(job_name)
                
        return flaky_jobs
        
    def _identify_bottlenecks(self, runs: List[Dict[str, Any]]) -> List[str]:
        """Identify jobs that slow down the pipeline"""
        job_durations = {}
        for run in runs:
            for job in run["jobs"]:
                duration = (job["completed_at"] - job["started_at"]).total_seconds()
                if job["name"] not in job_durations:
                    job_durations[job["name"]] = []
                job_durations[job["name"]].append(duration)
                
        # Find jobs with consistently high durations
        bottlenecks = []
        for job_name, durations in job_durations.items():
            avg_duration = sum(durations) / len(durations)
            if avg_duration > 300:  # Consider jobs taking more than 5 minutes
                bottlenecks.append(job_name)
                
        return bottlenecks
        
    def _analyze_resource_usage(self, runs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze resource usage patterns"""
        usage = {
            "cpu": {},
            "memory": {},
            "disk": {}
        }
        
        for run in runs:
            for job in run["jobs"]:
                if "resource_monitoring" in job:
                    resources = job["resource_monitoring"]
                    job_name = job["name"]
                    
                    if job_name not in usage["cpu"]:
                        usage["cpu"][job_name] = []
                    usage["cpu"][job_name].append(resources["cpu_percentage"])
                    
                    if job_name not in usage["memory"]:
                        usage["memory"][job_name] = []
                    usage["memory"][job_name].append(resources["memory_mb"])
                    
                    if job_name not in usage["disk"]:
                        usage["disk"][job_name] = []
                    usage["disk"][job_name].append(resources["disk_mb"])
                    
        # Calculate averages
        for resource in usage:
            for job_name in usage[resource]:
                values = usage[resource][job_name]
                usage[resource][job_name] = sum(values) / len(values)
                
        return usage
        
    def _analyze_cache_hits(self, runs: List[Dict[str, Any]]) -> Dict[str, float]:
        """Analyze cache effectiveness"""
        cache_stats = {}
        
        for run in runs:
            for job in run["jobs"]:
                if "steps" in job:
                    for step in job["steps"]:
                        if "cache" in step:
                            cache_key = f"{job['name']}_{step['name']}"
                            if cache_key not in cache_stats:
                                cache_stats[cache_key] = {"hits": 0, "misses": 0}
                            if step["cache"]["hit"]:
                                cache_stats[cache_key]["hits"] += 1
                            else:
                                cache_stats[cache_key]["misses"] += 1
                                
        # Calculate hit rates
        hit_rates = {}
        for cache_key, stats in cache_stats.items():
            total = stats["hits"] + stats["misses"]
            hit_rates[cache_key] = stats["hits"] / total if total > 0 else 0
            
        return hit_rates
        
    def _optimize_parallelization(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """Optimize job parallelization"""
        bottlenecks = metrics.get("bottleneck_jobs", [])
        
        optimizations = {
            "parallel_jobs": [],
            "matrix_configs": {}
        }
        
        for job in bottlenecks:
            if "test" in job.lower():
                # Suggest test parallelization
                optimizations["matrix_configs"][job] = {
                    "max-parallel": 4,
                    "split": ["unit", "integration", "e2e"]
                }
            else:
                # Suggest general parallelization
                optimizations["parallel_jobs"].append(job)
                
        return optimizations
        
    def _optimize_caching(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """Optimize caching strategy"""
        cache_hits = metrics.get("cache_effectiveness", {})
        
        optimizations = {
            "improve_caching": [],
            "cache_keys": {},
            "cache_paths": {}
        }
        
        for cache_key, hit_rate in cache_hits.items():
            if hit_rate < 0.8:  # Less than 80% hit rate
                job_name = cache_key.split("_")[0]
                optimizations["improve_caching"].append(job_name)
                optimizations["cache_keys"][job_name] = [
                    "${{ runner.os }}-${{ hashFiles('**/lockfile') }}",
                    "${{ runner.os }}"
                ]
                
        return optimizations
        
    def _optimize_resources(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """Optimize resource allocation"""
        resource_usage = metrics.get("resource_usage", {})
        
        optimizations = {
            "resource_classes": {},
            "environment_size": {}
        }
        
        for job_name, cpu_usage in resource_usage.get("cpu", {}).items():
            if cpu_usage > 80:
                optimizations["resource_classes"][job_name] = "large"
            elif cpu_usage < 30:
                optimizations["resource_classes"][job_name] = "small"
                
        return optimizations
        
    def _optimize_test_distribution(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """Optimize test distribution"""
        flaky_jobs = metrics.get("flaky_jobs", [])
        
        optimizations = {
            "test_splits": {},
            "retry_config": {}
        }
        
        for job in flaky_jobs:
            if "test" in job.lower():
                optimizations["retry_config"][job] = {
                    "max_retries": 2,
                    "retry_on": ["flaky", "timeout"]
                }
                
        return optimizations
        
    def _optimize_conditionals(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """Optimize conditional job execution"""
        job_stats = {}  # Would be populated with job execution statistics
        
        optimizations = {
            "conditional_config": {},
            "skip_conditions": {}
        }
        
        for job_name, stats in job_stats.items():
            if stats.get("changes_required", False):
                optimizations["conditional_config"][job_name] = {
                    "paths": ["relevant/path/**"],
                    "branches": ["main", "develop"]
                }
                
        return optimizations
        
    def _save_metrics(self, metrics: Dict[str, Any]):
        """Save pipeline metrics"""
        with open(self.metrics_file, 'w') as f:
            json.dump({
                "timestamp": datetime.now().isoformat(),
                "metrics": metrics
            }, f, indent=2)
            
    def _save_optimization_history(self, optimizations: Dict[str, Any]):
        """Save optimization history"""
        history = []
        if os.path.exists(self.optimization_history):
            with open(self.optimization_history, 'r') as f:
                history = json.load(f)
                
        history.append({
            "timestamp": datetime.now().isoformat(),
            "optimizations": optimizations
        })
        
        with open(self.optimization_history, 'w') as f:
            json.dump(history, f, indent=2)

def main():
    optimizer = PipelineOptimizer()
    metrics = optimizer.analyze_pipeline_metrics()
    optimizations = optimizer.optimize_pipeline(metrics)
    
    print("Pipeline Analysis Complete")
    print("Metrics:", json.dumps(metrics, indent=2))
    print("Optimizations:", json.dumps(optimizations, indent=2))

if __name__ == "__main__":
    main()
