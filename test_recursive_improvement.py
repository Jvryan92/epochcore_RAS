#!/usr/bin/env python3
"""
EpochCore RAS Recursive Improvement Framework Test Suite
Comprehensive test demonstrating all framework functionality
"""

import sys
import time
from datetime import datetime


def test_core_framework():
    """Test the core recursive improvement framework"""
    print("ğŸ”§ Testing Core Recursive Improvement Framework")
    print("=" * 60)
    
    from recursive_improvement import get_framework
    
    # Test framework initialization
    framework = get_framework()
    print(f"âœ… Framework initialized: {type(framework).__name__}")
    
    # Test basic status
    status = framework.get_status()
    print(f"âœ… Framework status: autonomous_mode={status['autonomous_mode']}")
    print(f"âœ… Registered subsystems: {len(status['registered_subsystems'])}")
    
    return framework


def test_subsystem_modules():
    """Test individual subsystem modules"""
    print("\nğŸ¤– Testing Subsystem Modules")
    print("=" * 60)
    
    # Test agent management
    from agent_management import initialize_agent_management, get_agent_status
    agent_hook = initialize_agent_management()
    print(f"âœ… Agent management initialized: {agent_hook.name}")
    
    agent_status = get_agent_status()
    print(f"   - Total agents: {agent_status['total_agents']}")
    print(f"   - Average performance: {agent_status['average_performance']:.2f}")
    
    # Test DAG management
    from dag_management import initialize_dag_management, get_dag_status
    dag_hook = initialize_dag_management()
    print(f"âœ… DAG management initialized: {dag_hook.name}")
    
    dag_status = get_dag_status()
    print(f"   - Total workflows: {dag_status['total_workflows']}")
    print(f"   - Success rate: {dag_status['avg_success_rate']:.1%}")
    
    # Test capsule management
    from capsule_metadata import initialize_capsule_management, get_capsule_status
    capsule_hook = initialize_capsule_management()
    print(f"âœ… Capsule management initialized: {capsule_hook.name}")
    
    capsule_status = get_capsule_status()
    print(f"   - Total capsules: {capsule_status['total_capsules']}")
    print(f"   - Integrity rate: {capsule_status['integrity_rate']:.1%}")
    
    # Test ethical reflection
    from ethical_reflection import initialize_ethical_reflection, get_ethical_status
    ethics_hook = initialize_ethical_reflection()
    print(f"âœ… Ethical reflection initialized: {ethics_hook.name}")
    
    ethics_status = get_ethical_status()
    print(f"   - Total rules: {ethics_status['total_rules']}")
    print(f"   - Decision confidence: {ethics_status['recent_decision_confidence']:.1%}")
    
    # Test ML optimization
    from ml_optimization import initialize_ml_optimization, get_ml_status
    ml_hook = initialize_ml_optimization()
    print(f"âœ… ML optimization initialized: {ml_hook.name}")
    
    ml_status = get_ml_status()
    print(f"   - Total models: {ml_status['system_metrics']['total_models']}")
    print(f"   - Average accuracy: {ml_status['system_metrics']['avg_accuracy']:.1%}")
    
    return [agent_hook, dag_hook, capsule_hook, ethics_hook, ml_hook]


def test_manual_improvements(framework):
    """Test manual improvement triggers"""
    print("\nğŸ”§ Testing Manual Improvement Triggers")
    print("=" * 60)
    
    # Test improvement of specific subsystem
    print("â†’ Testing agent improvement...")
    agent_result = framework.run_manual_improvement("agents")
    if agent_result["status"] == "success":
        print("âœ… Agent improvement successful")
        for improvement in agent_result.get("improvements", []):
            improvements_made = improvement["after_state"].get("improvements_made", [])
            if improvements_made:
                print(f"   - Made {len(improvements_made)} improvements")
    else:
        print(f"âœ— Agent improvement failed: {agent_result}")
    
    # Test improvement of all subsystems
    print("â†’ Testing system-wide improvement...")
    all_result = framework.run_manual_improvement()
    if all_result["status"] == "success":
        successful = sum(1 for r in all_result["subsystem_results"].values() 
                        if r["status"] == "success")
        total = all_result["total_subsystems"]
        print(f"âœ… System-wide improvement: {successful}/{total} subsystems improved")
        
        # Show some improvement details
        for subsystem, result in all_result["subsystem_results"].items():
            if result["status"] == "success" and "improvements" in result:
                improvement_count = sum(len(imp["after_state"].get("improvements_made", [])) 
                                      for imp in result["improvements"])
                if improvement_count > 0:
                    print(f"   - {subsystem}: {improvement_count} improvements")
    else:
        print(f"âœ— System-wide improvement failed: {all_result}")


def test_framework_status(framework):
    """Test framework status and metrics"""
    print("\nğŸ“Š Testing Framework Status and Metrics")
    print("=" * 60)
    
    status = framework.get_status()
    print(f"âœ… Framework Status:")
    print(f"   - Autonomous mode: {status['autonomous_mode']}")
    print(f"   - Registered subsystems: {len(status['registered_subsystems'])}")
    print(f"   - Recent improvements: {len(status['recent_improvements'])}")
    print(f"   - Total improvements: {status['total_improvements']}")
    
    print(f"\nğŸ“‹ Registered Subsystems:")
    for name, info in status['registered_subsystems'].items():
        enabled = "enabled" if info['enabled'] else "disabled"
        strategies = len(info['strategies'])
        print(f"   - {name.upper()}: {enabled}, {strategies} strategies")
    
    # Test metrics
    metrics = framework.get_metrics()
    recent_improvements = metrics.get_recent_improvements(24)
    print(f"\nğŸ“ˆ Recent Metrics (24h):")
    print(f"   - Recent improvements: {len(recent_improvements)}")
    
    if recent_improvements:
        successful = sum(1 for imp in recent_improvements if imp["success"])
        print(f"   - Success rate: {successful}/{len(recent_improvements)} ({successful/len(recent_improvements):.1%})")


def test_autonomous_mode(framework):
    """Test autonomous mode functionality"""
    print("\nğŸ¤– Testing Autonomous Mode")
    print("=" * 60)
    
    print("â†’ Starting autonomous mode...")
    framework.start_autonomous_mode()
    print("âœ… Autonomous mode started")
    
    # Wait a short time to see if it's working
    print("â†’ Waiting 3 seconds to observe autonomous operation...")
    time.sleep(3)
    
    status = framework.get_status()
    print(f"âœ… Autonomous mode active: {status['autonomous_mode']}")
    
    print("â†’ Stopping autonomous mode...")
    framework.stop_autonomous_mode()
    print("âœ… Autonomous mode stopped")
    
    final_status = framework.get_status()
    print(f"âœ… Autonomous mode inactive: {not final_status['autonomous_mode']}")


def test_individual_subsystem_demos():
    """Test each subsystem's individual demo functionality"""
    print("\nğŸ¯ Testing Individual Subsystem Demos")
    print("=" * 60)
    
    print("â†’ Testing Agent Management Demo...")
    try:
        from agent_management import improve_agent_performance
        agent_result = improve_agent_performance()
        print(f"âœ… Agent demo: {agent_result['status']}")
    except Exception as e:
        print(f"âœ— Agent demo failed: {e}")
    
    print("â†’ Testing DAG Management Demo...")
    try:
        from dag_management import improve_dag_performance
        dag_result = improve_dag_performance()
        print(f"âœ… DAG demo: {dag_result['status']}")
    except Exception as e:
        print(f"âœ— DAG demo failed: {e}")
    
    print("â†’ Testing Capsule Management Demo...")
    try:
        from capsule_metadata import improve_capsule_storage
        capsule_result = improve_capsule_storage()
        print(f"âœ… Capsule demo: {capsule_result['status']}")
    except Exception as e:
        print(f"âœ— Capsule demo failed: {e}")
    
    print("â†’ Testing Ethical Reflection Demo...")
    try:
        from ethical_reflection import improve_ethical_system, evaluate_scenario
        ethics_result = improve_ethical_system()
        print(f"âœ… Ethics demo: {ethics_result['status']}")
        
        # Test scenario evaluation
        test_scenario = {
            "description": "AI system collecting user data",
            "stakeholders": ["users", "company"],
            "context": {"data_type": "personal", "purpose": "analytics"}
        }
        eval_result = evaluate_scenario(test_scenario)
        print(f"âœ… Scenario evaluation: confidence {eval_result['confidence_score']:.1%}")
    except Exception as e:
        print(f"âœ— Ethics demo failed: {e}")
    
    print("â†’ Testing ML Optimization Demo...")
    try:
        from ml_optimization import improve_ml_system
        ml_result = improve_ml_system()
        print(f"âœ… ML demo: {ml_result['status']}")
    except Exception as e:
        print(f"âœ— ML demo failed: {e}")


def test_integration_with_existing_system():
    """Test integration with the existing integration.py system"""
    print("\nğŸ”— Testing Integration with Existing System")
    print("=" * 60)
    
    # Test the integration functions
    from integration import setup_demo, run_workflow, get_status, validate_system
    
    print("â†’ Testing setup_demo integration...")
    setup_result = setup_demo()
    print(f"âœ… Setup demo: {setup_result['status']}")
    print(f"   - Components initialized: {setup_result['components_initialized']}")
    print(f"   - Improvement hooks: {setup_result['improvement_hooks']}")
    
    print("â†’ Testing run_workflow integration...")
    workflow_result = run_workflow()
    print(f"âœ… Workflow: {workflow_result['status']}")
    print(f"   - Tasks completed: {workflow_result['tasks_completed']}")
    print(f"   - Subsystems improved: {workflow_result['subsystems_improved']}")
    
    print("â†’ Testing status integration...")
    get_status()  # This prints its own status
    print("âœ… Status integration working")
    
    print("â†’ Testing validation integration...")
    validation_result = validate_system()
    print(f"âœ… Validation: {validation_result['status']}")


def main():
    """Run comprehensive test suite"""
    print("ğŸš€ EpochCore RAS Recursive Improvement Framework Test Suite")
    print("=" * 80)
    print(f"Started at: {datetime.now()}")
    print()
    
    try:
        # Test 1: Core framework
        framework = test_core_framework()
        
        # Test 2: Subsystem modules
        subsystem_hooks = test_subsystem_modules()
        
        # Test 3: Manual improvements
        test_manual_improvements(framework)
        
        # Test 4: Framework status
        test_framework_status(framework)
        
        # Test 5: Autonomous mode
        test_autonomous_mode(framework)
        
        # Test 6: Individual demos
        test_individual_subsystem_demos()
        
        # Test 7: Integration
        test_integration_with_existing_system()
        
        print(f"\nğŸ‰ All Tests Completed Successfully!")
        print("=" * 80)
        print(f"Finished at: {datetime.now()}")
        print()
        print("ğŸ“‹ Summary:")
        print(f"   - Core framework: âœ… Working")
        print(f"   - Subsystem modules: âœ… 5 modules initialized")
        print(f"   - Manual improvements: âœ… Working")
        print(f"   - Framework status: âœ… Working")
        print(f"   - Autonomous mode: âœ… Working")
        print(f"   - Individual demos: âœ… Working")
        print(f"   - Integration: âœ… Working")
        print()
        print("ğŸš€ Recursive Improvement Framework is fully operational!")
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ Test suite failed with error: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())